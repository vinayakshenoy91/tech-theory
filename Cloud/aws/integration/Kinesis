
- It is a managed alternative to Apache Kafka
- Good for app logs, metrics, IoT, clickStreams.
- Great for realtime big-data
- Compatible with stream processign framework like Spark, Nifi, etc
- Data is auto replicated to 3 AZ
- Kinesis stream as a highly-durable linked list in the cloud.
- you would typically use either Kinesis or SQS when you want to enqueue records for asynchronous processing.

Kinesis vs SQS:
--------------
- SQS can only have one consumer, while Kinesis can have many.
- Once an SQS message gets consumed, it gets deleted from the queue. But Kinesis records get added to a 
list in a stable order, 
and any number of consumers can read a copy of the stream by keeping a cursor over this never-ending list.
- Multiple consumers don’t affect each other, and if one falls behind, it doesn’t slow down the other consumers.
Whenever consumers read data out of Kinesis, they will always get their records in the same order.
- Putting 1 KB messages in SQS at an average rate of 500 messages per second will cost you $34.56 per day. 
A Kinesis stream with 50% capacity headroom can handle that same volume for just $0.96 per day. So there can be 
about a massive difference in cost.'

1) Kinesis Streams:
----------------------
- Low latency stream ingest at scale.
- Kinesis streams are optimized for sequential reads and sequential writes.
- Records get added to the end of a file and read always happens sequentially from a pointer on that file.
- Unlike SQS, records in a Kinesis stream don’t get deleted when consumed, so it’s a pure append-only data structure 
behind the scenes.
- Data simply ages out of a Kinesis stream once it exceeds its retention period, which is 24 hours by default.
- Streams are divided into ordered shards / partitions
- Data retention is 1 day default but can go upto 7 days
- Reprocess or replay data
- Multiple consumers can consume same stream
- once data is inserted it cant be deleted (immutability)
- One stream -> diff shards
- 1000 messages/s at write per shard
- 2MB/s at read per SHARD
- Billing is per shard priovisioned
- Number of shard evovle over time.
- Records are ordered per shard
- Same key goes to same partition 
- Use batching and put record so reduce costs and increase throughput
- priovisionedThoroughput exceeded exception-> retry or exponential backoff, more shard, partition key is good
- VPC endpoints available for kinesis to access within VPC

2) Kinesis Analytics:
---------------------
- Perform real-time analytics on streams using SQL

3) Kinesis Firehose:
--------------------
- Load streams into S3, Redshift, ElasticSearch, splunk
- Near realtime
- Support data formats, conversions, transformationa nd compression
- Pay for amount of data goign through firehose

# Not easy to use:
------------------
On the other hand, Kinesis is not as easy to use as SQS. While with SQS you can simply enqueue as many messages as you want
without having to 
worry about capacity or throttling limits, a Kinesis stream is made up of slices of capacity called shards, and it’s up to you to 
figure out how 
many shards you need, monitor shard utilization, add shards, and figure out the best way to route records to shards 
so that they get approximately an equivalent amount of traffic. And unfortunately, all of this is a significant operational burden.

Commands:
----------
aws kinesis help
aws kinesis list-streams
aws kinesis describe-streams --stream-name <my-first-stream>
aws kinesis put-record --stream-name my-first-stream --data "user-signup" --partition-key user_123


Usecase:
--------
- You are looking to process tens of thousands of orders per second and you would like 
to make sure the orders are going to be processed in the order they were placed for each customer.
Kinesis Data Streams will give us the scale, and also allow us to have ordering by customer_id,
using customer_id as our partition key


